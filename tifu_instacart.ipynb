{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11571c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from retrieval_importance import learn_importance, encode_retrievals\n",
    "from applications.nbr.tifuknn import TIFUKNN\n",
    "from applications.nbr.data import index_consecutive\n",
    "from applications.nbr.metrics import hitrate_at_n, recall_at_n, precision_at_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341b8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(retrieval, user_vector):    \n",
    "\n",
    "    predictions = [(item, weight) for item, weight in enumerate(user_vector) if weight > 0.0]    \n",
    "    prediction_sorted = sorted(predictions, key=lambda pred: pred[1], reverse=True)\n",
    "    top_items = [pred[0] for pred in prediction_sorted]\n",
    "    \n",
    "    recall = recall_at_n(retrieval['next_basket'], top_items, 5)    \n",
    "    \n",
    "    return np.around(recall, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226b6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(tifu, users_to_retain, evaluation_baskets, num_eval_users, name):\n",
    "\n",
    "    hitrates_dirty = []\n",
    "    recalls_dirty = []\n",
    "    precisions_dirty = []\n",
    "    \n",
    "    hitrates_clean = []\n",
    "    recalls_clean = []\n",
    "    precisions_clean = []\n",
    "    \n",
    "    for user in range(0, num_eval_users):\n",
    "        \n",
    "        next_basket_items = list(evaluation_baskets[evaluation_baskets.user_id==user].item_id)    \n",
    "\n",
    "        k = 10 # TODO should be a param\n",
    "        n = 5  # TODO should be a param\n",
    "        all_neighbors = tifu.retrieve_for(user)\n",
    "        \n",
    "        # Original prediction\n",
    "        prediction = tifu.predict(user, all_neighbors[:k], n)\n",
    "        \n",
    "        cleaned_neighbors = [neighbor for neighbor in all_neighbors if neighbor in users_to_retain]\n",
    "        prediction_clean = tifu.predict(user, cleaned_neighbors[:k], n)\n",
    "\n",
    "        \n",
    "        hitrates_dirty.append(hitrate_at_n(next_basket_items, prediction, n))\n",
    "        recalls_dirty.append(recall_at_n(next_basket_items, prediction, n))     \n",
    "        precisions_dirty.append(precision_at_n(next_basket_items, prediction, n))             \n",
    "        \n",
    "        hitrates_clean.append(hitrate_at_n(next_basket_items, prediction_clean, n))\n",
    "        recalls_clean.append(recall_at_n(next_basket_items, prediction_clean, n))\n",
    "        precisions_clean.append(precision_at_n(next_basket_items, prediction_clean, n))  \n",
    "    \n",
    "    print(f'{name}, hitrate@5_dirty={np.mean(hitrates_dirty):.5f}, hitrate@5_clean={np.mean(hitrates_clean):.5f}') \n",
    "    print(f'{name}, precision@5_dirty={np.mean(precisions_dirty):.5f}, precision@5_clean={np.mean(precisions_clean):.5f}')     \n",
    "    print(f'{name}, recall@5_dirty={np.mean(recalls_dirty):.5f}, recall@5_clean={np.mean(recalls_clean):.5f}')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0db7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(seed, num_users, num_eval_users, threshold, all_train_baskets, all_validation_baskets, all_test_baskets):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    unique_user_ids = list(all_train_baskets.user_id.unique())\n",
    "    sampled_users = np.random.choice(unique_user_ids, num_users)\n",
    "    train_baskets = all_train_baskets[all_train_baskets.user_id.isin(sampled_users)]\n",
    "    validation_baskets = all_validation_baskets[all_validation_baskets.user_id.isin(sampled_users)]\n",
    "    test_baskets = all_test_baskets[all_test_baskets.user_id.isin(sampled_users)] \n",
    "\n",
    "    index_consecutive('user_id', [train_baskets, validation_baskets, test_baskets])\n",
    "    index_consecutive('item_id', [train_baskets, validation_baskets, test_baskets])    \n",
    "    \n",
    "    tifu = TIFUKNN(train_baskets, k=10, kplus=40)\n",
    "\n",
    "\n",
    "    retrievals = []\n",
    "    for user in range(0, num_eval_users):\n",
    "\n",
    "        next_basket = list(validation_baskets[validation_baskets.user_id==user].item_id)\n",
    "\n",
    "        neighbors = tifu.retrieve_for(user)\n",
    "        neighbor_representations = [tifu.representation(neighbor) for neighbor in neighbors]       \n",
    "\n",
    "        if len(next_basket) > 0:    \n",
    "            retrievals.append({\n",
    "                'user': user,\n",
    "                'next_basket': next_basket,\n",
    "                'neighbors': neighbors,\n",
    "                'neighbor_representations': neighbor_representations,\n",
    "            })    \n",
    "\n",
    "    encoded_retrievals, mapping = encode_retrievals(retrievals, \"neighbors\", \"neighbor_representations\", utility)   \n",
    "\n",
    "    v = learn_importance(encoded_retrievals, k=10, learning_rate=0.1, num_steps=500)\n",
    "\n",
    "    users_to_retain = set([user for (user, value) in enumerate(v) if value >= threshold])\n",
    "    users_to_retain.update(range(0, num_eval_users))\n",
    "\n",
    "\n",
    "    print(f'-----SEED={seed}-----')\n",
    "    cleaned_train_baskets = train_baskets[train_baskets.user_id.isin(users_to_retain)]    \n",
    "    print(f'datasize_dirty={len(train_baskets)}, datasize_clean={len(cleaned_train_baskets)}')\n",
    "    \n",
    "    compare(tifu, users_to_retain, validation_baskets, num_eval_users, 'validation')\n",
    "    compare(tifu, users_to_retain, test_baskets, num_eval_users, 'test')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708e71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_baskets = pd.read_csv(\"applications/nbr/data/instacart_30k/train_baskets.csv.gz\")\n",
    "all_validation_baskets = pd.read_csv(\"applications/nbr/data/instacart_30k/valid_baskets.csv\")\n",
    "all_test_baskets = pd.read_csv(\"applications/nbr/data/instacart_30k/test_baskets.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fa9c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----SEED=42-----\n",
      "datasize_dirty=157463, datasize_clean=87144\n",
      "validation, hitrate@5_dirty=0.88000, hitrate@5_clean=0.88000\n",
      "validation, precision@5_dirty=0.42800, precision@5_clean=0.43400\n",
      "validation, recall@5_dirty=0.22702, recall@5_clean=0.22959\n",
      "test, hitrate@5_dirty=0.77000, hitrate@5_clean=0.78000\n",
      "test, precision@5_dirty=0.36600, precision@5_clean=0.36800\n",
      "test, recall@5_dirty=0.19187, recall@5_clean=0.19359\n",
      "-----SEED=16-----\n",
      "datasize_dirty=156897, datasize_clean=85034\n",
      "validation, hitrate@5_dirty=0.92000, hitrate@5_clean=0.90000\n",
      "validation, precision@5_dirty=0.45600, precision@5_clean=0.45000\n",
      "validation, recall@5_dirty=0.22608, recall@5_clean=0.22487\n",
      "test, hitrate@5_dirty=0.84000, hitrate@5_clean=0.85000\n",
      "test, precision@5_dirty=0.40000, precision@5_clean=0.40600\n",
      "test, recall@5_dirty=0.20532, recall@5_clean=0.20762\n",
      "-----SEED=1812-----\n",
      "datasize_dirty=163196, datasize_clean=87367\n",
      "validation, hitrate@5_dirty=0.78000, hitrate@5_clean=0.76000\n",
      "validation, precision@5_dirty=0.38200, precision@5_clean=0.38000\n",
      "validation, recall@5_dirty=0.19465, recall@5_clean=0.19364\n",
      "test, hitrate@5_dirty=0.78000, hitrate@5_clean=0.77000\n",
      "test, precision@5_dirty=0.36400, precision@5_clean=0.36600\n",
      "test, recall@5_dirty=0.18271, recall@5_clean=0.18620\n",
      "-----SEED=1312-----\n",
      "datasize_dirty=162644, datasize_clean=79877\n",
      "validation, hitrate@5_dirty=0.86000, hitrate@5_clean=0.87000\n",
      "validation, precision@5_dirty=0.42600, precision@5_clean=0.42200\n",
      "validation, recall@5_dirty=0.21690, recall@5_clean=0.21442\n",
      "test, hitrate@5_dirty=0.83000, hitrate@5_clean=0.82000\n",
      "test, precision@5_dirty=0.37200, precision@5_clean=0.36800\n",
      "test, recall@5_dirty=0.20305, recall@5_clean=0.20192\n",
      "-----SEED=35-----\n",
      "datasize_dirty=162235, datasize_clean=87096\n",
      "validation, hitrate@5_dirty=0.75000, hitrate@5_clean=0.76000\n",
      "validation, precision@5_dirty=0.37400, precision@5_clean=0.37800\n",
      "validation, recall@5_dirty=0.18795, recall@5_clean=0.18933\n",
      "test, hitrate@5_dirty=0.85000, hitrate@5_clean=0.85000\n",
      "test, precision@5_dirty=0.39800, precision@5_clean=0.40400\n",
      "test, recall@5_dirty=0.20391, recall@5_clean=0.20344\n"
     ]
    }
   ],
   "source": [
    "for seed in [42, 16, 1812, 1312, 35]:\n",
    "    experiment(seed, 1000, 100, 0.5, all_train_baskets, all_validation_baskets, all_test_baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e1a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
